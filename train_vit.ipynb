{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2955c40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets, models\n",
    "import torchvision.utils\n",
    "import os, fnmatch\n",
    "from affine import Affine\n",
    "import rasterio\n",
    "from datetime import datetime\n",
    "import cv2\n",
    "from skimage import color\n",
    "import json\n",
    "from tifffile import imwrite\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import defaultdict\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "import copy\n",
    "import math\n",
    "import csv\n",
    "import albumentations as A\n",
    "from albumentations import augmentations\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# warnings.filterwarnings(action='once')\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63c83097",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../../mmsegmentation')\n",
    "\n",
    "from mmseg.apis import inference_segmentor, init_segmentor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da2fec15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET\n",
    "\n",
    "import mmcv\n",
    "sys.path.append('../../mmsegmentation/')\n",
    "import mmseg\n",
    "from mmseg.apis import inference_segmentor, init_segmentor, show_result_pyplot\n",
    "from mmseg.core.evaluation import get_palette\n",
    "from mmseg.datasets.builder import DATASETS\n",
    "from mmseg.datasets.custom import CustomDataset\n",
    "\n",
    "data_root = '/home/jovyan/fominaav/CloudsDetection/masker/mmsegmentation/data/my_dataset/'\n",
    "img_dir = 'images'\n",
    "ann_dir = 'annotations'\n",
    "classes = ('Background', 'Clouds', 'Shadows', 'Snow')\n",
    "palette = [[128, 128, 128], [129, 127, 38], [120, 69, 125], [53, 125, 34]]\n",
    "\n",
    "@DATASETS.register_module()\n",
    "class ALCD(CustomDataset):\n",
    "    CLASSES = classes\n",
    "    PALETTE = palette\n",
    "    def __init__(self, split, **kwargs):\n",
    "        super().__init__(img_suffix='.jpg', seg_map_suffix='.png', \n",
    "                     split=split, **kwargs)\n",
    "        assert osp.exists(self.img_dir) and self.split is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6daece94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIG\n",
    "\n",
    "from mmcv import Config\n",
    "cfg = Config.fromfile('/home/jovyan/fominaav/CloudsDetection/masker/mmsegmentation/configs/vit/upernet_vit-b16_mln_512x512_80k_ade20k.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8ef31a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "norm_cfg = dict(type='BN', requires_grad=True)\n",
      "model = dict(\n",
      "    type='EncoderDecoder',\n",
      "    pretrained='pretrain/vit_base_patch16_224.pth',\n",
      "    backbone=dict(\n",
      "        type='VisionTransformer',\n",
      "        img_size=(512, 512),\n",
      "        patch_size=16,\n",
      "        in_channels=3,\n",
      "        embed_dims=768,\n",
      "        num_layers=12,\n",
      "        num_heads=12,\n",
      "        mlp_ratio=4,\n",
      "        out_indices=(2, 5, 8, 11),\n",
      "        qkv_bias=True,\n",
      "        drop_rate=0.0,\n",
      "        attn_drop_rate=0.0,\n",
      "        drop_path_rate=0.0,\n",
      "        with_cls_token=True,\n",
      "        norm_cfg=dict(type='BN', requires_grad=True),\n",
      "        act_cfg=dict(type='GELU'),\n",
      "        norm_eval=False,\n",
      "        interpolate_mode='bicubic'),\n",
      "    neck=dict(\n",
      "        type='MultiLevelNeck',\n",
      "        in_channels=[768, 768, 768, 768],\n",
      "        out_channels=768,\n",
      "        scales=[4, 2, 1, 0.5]),\n",
      "    decode_head=dict(\n",
      "        type='UPerHead',\n",
      "        in_channels=[768, 768, 768, 768],\n",
      "        in_index=[0, 1, 2, 3],\n",
      "        pool_scales=(1, 2, 3, 6),\n",
      "        channels=512,\n",
      "        dropout_ratio=0.1,\n",
      "        num_classes=4,\n",
      "        norm_cfg=dict(type='BN', requires_grad=True),\n",
      "        align_corners=False,\n",
      "        loss_decode=dict(\n",
      "            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0)),\n",
      "    auxiliary_head=dict(\n",
      "        type='FCNHead',\n",
      "        in_channels=768,\n",
      "        in_index=3,\n",
      "        channels=256,\n",
      "        num_convs=1,\n",
      "        concat_input=False,\n",
      "        dropout_ratio=0.1,\n",
      "        num_classes=150,\n",
      "        norm_cfg=dict(type='SyncBN', requires_grad=True),\n",
      "        align_corners=False,\n",
      "        loss_decode=dict(\n",
      "            type='CrossEntropyLoss', use_sigmoid=False, loss_weight=0.4)),\n",
      "    train_cfg=dict(),\n",
      "    test_cfg=dict(mode='whole'))\n",
      "dataset_type = 'ALCD'\n",
      "data_root = '/home/jovyan/fominaav/CloudsDetection/masker/mmsegmentation/data/my_dataset/'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[0.3965, 0.4287, 0.3811], std=[0.279, 0.2724, 0.275], to_rgb=True)\n",
      "crop_size = (512, 512)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations'),\n",
      "    dict(type='Resize', img_scale=(512, 512), ratio_range=(0.5, 2.0)),\n",
      "    dict(type='RandomCrop', crop_size=(512, 512), cat_max_ratio=0.75),\n",
      "    dict(type='RandomFlip', flip_ratio=0.5),\n",
      "    dict(type='PhotoMetricDistortion'),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[0.3965, 0.4287, 0.3811],\n",
      "        std=[0.279, 0.2724, 0.275],\n",
      "        to_rgb=True),\n",
      "    dict(type='Pad', size=(512, 512), pad_val=0, seg_pad_val=255),\n",
      "    dict(type='DefaultFormatBundle'),\n",
      "    dict(type='Collect', keys=['img', 'gt_semantic_seg'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='MultiScaleFlipAug',\n",
      "        img_scale=(512, 512),\n",
      "        flip=False,\n",
      "        transforms=[\n",
      "            dict(type='Resize', keep_ratio=True),\n",
      "            dict(type='RandomFlip'),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[0.3965, 0.4287, 0.3811],\n",
      "                std=[0.279, 0.2724, 0.275],\n",
      "                to_rgb=True),\n",
      "            dict(type='ImageToTensor', keys=['img']),\n",
      "            dict(type='Collect', keys=['img'])\n",
      "        ])\n",
      "]\n",
      "data = dict(\n",
      "    samples_per_gpu=8,\n",
      "    workers_per_gpu=8,\n",
      "    train=dict(\n",
      "        type='ALCD',\n",
      "        data_root=\n",
      "        '/home/jovyan/fominaav/CloudsDetection/masker/mmsegmentation/data/my_dataset/',\n",
      "        img_dir='images',\n",
      "        ann_dir='annotations',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations'),\n",
      "            dict(type='Resize', img_scale=(512, 512), ratio_range=(0.5, 2.0)),\n",
      "            dict(type='RandomCrop', crop_size=(512, 512), cat_max_ratio=0.75),\n",
      "            dict(type='RandomFlip', flip_ratio=0.5),\n",
      "            dict(type='PhotoMetricDistortion'),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[0.3965, 0.4287, 0.3811],\n",
      "                std=[0.279, 0.2724, 0.275],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size=(512, 512), pad_val=0, seg_pad_val=255),\n",
      "            dict(type='DefaultFormatBundle'),\n",
      "            dict(type='Collect', keys=['img', 'gt_semantic_seg'])\n",
      "        ],\n",
      "        split='splits/train.txt'),\n",
      "    val=dict(\n",
      "        type='ALCD',\n",
      "        data_root=\n",
      "        '/home/jovyan/fominaav/CloudsDetection/masker/mmsegmentation/data/my_dataset/',\n",
      "        img_dir='images',\n",
      "        ann_dir='annotations',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(512, 512),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[0.3965, 0.4287, 0.3811],\n",
      "                        std=[0.279, 0.2724, 0.275],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ],\n",
      "        split='splits/val.txt'),\n",
      "    test=dict(\n",
      "        type='ALCD',\n",
      "        data_root=\n",
      "        '/home/jovyan/fominaav/CloudsDetection/masker/mmsegmentation/data/my_dataset/',\n",
      "        img_dir='images',\n",
      "        ann_dir='annotations',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(512, 512),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[0.3965, 0.4287, 0.3811],\n",
      "                        std=[0.279, 0.2724, 0.275],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ],\n",
      "        split='splits/val.txt'))\n",
      "log_config = dict(\n",
      "    interval=200, hooks=[dict(type='TextLoggerHook', by_epoch=False)])\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = None\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "cudnn_benchmark = True\n",
      "optimizer = dict(\n",
      "    type='AdamW',\n",
      "    lr=6e-05,\n",
      "    betas=(0.9, 0.999),\n",
      "    weight_decay=0.01,\n",
      "    paramwise_cfg=dict(\n",
      "        custom_keys=dict(\n",
      "            pos_embed=dict(decay_mult=0.0),\n",
      "            cls_token=dict(decay_mult=0.0),\n",
      "            norm=dict(decay_mult=0.0))))\n",
      "optimizer_config = dict()\n",
      "lr_config = dict(\n",
      "    policy='poly',\n",
      "    warmup='linear',\n",
      "    warmup_iters=1500,\n",
      "    warmup_ratio=1e-06,\n",
      "    power=1.0,\n",
      "    min_lr=0.0,\n",
      "    by_epoch=False)\n",
      "runner = dict(type='IterBasedRunner', max_iters=5000)\n",
      "checkpoint_config = dict(\n",
      "    by_epoch=False,\n",
      "    interval=200,\n",
      "    meta=dict(\n",
      "        CLASSES=('background', 'clouds', 'clouds_shadows', 'Snow'),\n",
      "        PALETTE=[[128, 128, 128], [129, 127, 38], [120, 69, 125],\n",
      "                 [53, 125, 34]]))\n",
      "evaluation = dict(interval=200, metric='mIoU', pre_eval=True)\n",
      "work_dir = '/home/jovyan/fominaav/CloudsDetection/masker/notebooks/work_dirs/vit'\n",
      "seed = 0\n",
      "gpu_ids = [0]\n",
      "device = 'cuda'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from mmseg.apis import set_random_seed\n",
    "from mmseg.utils import get_device\n",
    "\n",
    "# add CLASSES and PALETTE to checkpoint\n",
    "cfg.checkpoint_config.meta = dict(\n",
    "    CLASSES=classes,\n",
    "    PALETTE=palette)\n",
    "\n",
    "# Since we use only one GPU, BN is used instead of SyncBN\n",
    "cfg.norm_cfg = dict(type='BN', requires_grad=True)\n",
    "cfg.model.backbone.norm_cfg = cfg.norm_cfg\n",
    "cfg.model.decode_head.norm_cfg = cfg.norm_cfg\n",
    "# modify num classes of the model in decode/auxiliary head\n",
    "cfg.model.decode_head.num_classes = 4\n",
    "\n",
    "# Modify dataset type and path\n",
    "cfg.dataset_type = 'ALCD'\n",
    "cfg.data_root = data_root\n",
    "\n",
    "cfg.data.samples_per_gpu = 32\n",
    "cfg.data.workers_per_gpu=8\n",
    "\n",
    "cfg.img_norm_cfg = dict(\n",
    "    mean=[0.3965, 0.4287, 0.3811], std=[0.2790, 0.2724, 0.2750], to_rgb=True)\n",
    "cfg.crop_size = (512, 512)\n",
    "cfg.train_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(type='LoadAnnotations'),\n",
    "    dict(type='Resize', img_scale=(512, 512), ratio_range=(0.5, 2.0)),\n",
    "    dict(type='RandomCrop', crop_size=cfg.crop_size, cat_max_ratio=0.75),\n",
    "    dict(type='RandomFlip', flip_ratio=0.5),\n",
    "    dict(type='PhotoMetricDistortion'),\n",
    "    dict(type='Normalize', **cfg.img_norm_cfg),\n",
    "    dict(type='Pad', size=cfg.crop_size, pad_val=0, seg_pad_val=255),\n",
    "    dict(type='DefaultFormatBundle'),\n",
    "    dict(type='Collect', keys=['img', 'gt_semantic_seg']),\n",
    "]\n",
    "\n",
    "cfg.test_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(\n",
    "        type='MultiScaleFlipAug',\n",
    "        img_scale=(512, 512),\n",
    "        # img_ratios=[0.5, 0.75, 1.0, 1.25, 1.5, 1.75],\n",
    "        flip=False,\n",
    "        transforms=[\n",
    "            dict(type='Resize', keep_ratio=True),\n",
    "            dict(type='RandomFlip'),\n",
    "            dict(type='Normalize', **cfg.img_norm_cfg),\n",
    "            dict(type='ImageToTensor', keys=['img']),\n",
    "            dict(type='Collect', keys=['img']),\n",
    "        ])\n",
    "]\n",
    "\n",
    "\n",
    "cfg.data.train.type = cfg.dataset_type\n",
    "cfg.data.train.data_root = cfg.data_root\n",
    "cfg.data.train.img_dir = img_dir\n",
    "cfg.data.train.ann_dir = ann_dir\n",
    "cfg.data.train.pipeline = cfg.train_pipeline\n",
    "cfg.data.train.split = 'splits/train.txt'\n",
    "\n",
    "cfg.data.val.type = cfg.dataset_type\n",
    "cfg.data.val.data_root = cfg.data_root\n",
    "cfg.data.val.img_dir = img_dir\n",
    "cfg.data.val.ann_dir = ann_dir\n",
    "cfg.data.val.pipeline = cfg.test_pipeline\n",
    "cfg.data.val.split = 'splits/val.txt'\n",
    "\n",
    "cfg.data.test.type = cfg.dataset_type\n",
    "cfg.data.test.data_root = cfg.data_root\n",
    "cfg.data.test.img_dir = img_dir\n",
    "cfg.data.test.ann_dir = ann_dir\n",
    "cfg.data.test.pipeline = cfg.test_pipeline\n",
    "cfg.data.test.split = 'splits/val.txt'\n",
    "\n",
    "# Set up working dir to save files and logs.\n",
    "cfg.work_dir = '/home/jovyan/fominaav/CloudsDetection/masker/notebooks/work_dirs/vit'\n",
    "\n",
    "cfg.runner.max_iters = 5000\n",
    "cfg.log_config.interval = 100\n",
    "cfg.evaluation.interval = 100\n",
    "cfg.checkpoint_config.interval = 100\n",
    "\n",
    "# Set seed to facitate reproducing the result\n",
    "cfg.seed = 0\n",
    "cfg.gpu_ids = [0]\n",
    "cfg.device = get_device()\n",
    "\n",
    "# Let's have a look at the final config used for training\n",
    "print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037e313f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('vit_config.py', 'w') as f:\n",
    "    f.write(cfg.pretty_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766d3c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN\n",
    "import os.path as osp\n",
    "from mmseg.datasets import build_dataset\n",
    "from mmseg.models import build_segmentor\n",
    "from mmseg.apis import train_segmentor\n",
    "\n",
    "\n",
    "# Build the dataset\n",
    "datasets = [build_dataset(cfg.data.train)]\n",
    "\n",
    "# Build the detector\n",
    "model = build_segmentor(cfg.model)\n",
    "# Add an attribute for visualization convenience\n",
    "model.CLASSES = datasets[0].CLASSES\n",
    "\n",
    "# Create work_dir\n",
    "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
    "train_segmentor(model, datasets, cfg, distributed=False, validate=True, \n",
    "                meta=dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ad1dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = mmcv.imread('/home/jovyan/fominaav/CloudsDetection/masker/mmsegmentation/data/low_res_dataset/images/20171013T081959_204.jpg')\n",
    "model.cfg = cfg\n",
    "result = inference_segmentor(model, img)\n",
    "show_result_pyplot(model, img, result, palette, fig_size=(6, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cd7952",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
